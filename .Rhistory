alternative = "greater", paired = TRUE) # one-sided
lppRealAvMin_d <- cohens_d(x = dataLPP$Av_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Min_allTr[dataLPP$usGroup == "real"],
paired = TRUE)
lppRealAvMin_BF <- ttestBF(x = dataLPP$Av_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Min_allTr[dataLPP$usGroup == "real"],
nullInterval = c(0, Inf), paired = TRUE) # one-sided x > y
# CS+neu vs CS-
lppRealNeuMin_t <- t.test(x = dataLPP$Neu_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Min_allTr[dataLPP$usGroup == "real"],
alternative = "two.sided", paired = TRUE) # one-sided
lppRealNeuMin_d <- cohens_d(x = dataLPP$Neu_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Min_allTr[dataLPP$usGroup == "real"],
paired = TRUE)
lppRealNeuMin_BF <- ttestBF(x = dataLPP$Neu_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Min_allTr[dataLPP$usGroup == "real"],
nullInterval = NULL, paired = TRUE) # one-sided x > y
########################################
### Across groups - primary analyses ###
########################################
# descriptive statistics for LPP ratings across conditioning groups
describe(dataLPP)
# frequentist ANOVA on LPP across conditioning groups
anovaLPP <- ezANOVA(
data = dataLPPLong[dataLPPLong$time == "allTr",],
dv = LPP,
wid = partInd,
within = .(CS),
between = .(usGroup),
type = 3,
detailed = TRUE
); anovaLPP$ANOVA$pEtaSq <- c(anovaLPP$ANOVA$SSn[1] /
(anovaLPP$ANOVA$SSd[1]+anovaLPP$ANOVA$SSn[1]),
anovaLPP$ANOVA$SSn[2] /
(anovaLPP$ANOVA$SSd[2]+anovaLPP$ANOVA$SSn[2]),
anovaLPP$ANOVA$SSn[3] /
(anovaLPP$ANOVA$SSd[3]+anovaLPP$ANOVA$SSn[3]),
anovaLPP$ANOVA$SSn[4] /
(anovaLPP$ANOVA$SSd[4]+anovaLPP$ANOVA$SSn[4])
); print(anovaLPP)
# bayesian ANOVA on LPP across conditioning groups
set.seed(rngSeed); anovaBFLPP <- anovaBF(
formula = LPP ~ usGroup*CS + partInd,
data = dataLPPLong[dataLPPLong$time == "allTr",],
whichRandom = "partInd",
whichModels = "all",
iterations = 100000
); print(anovaBFLPP)
# inclusion factors for bayesian ANOVA effects
bf_inclusion(anovaBFLPP)
# quick graph of group x CS ANOVA on LPP
ezPlot(
data = dataLPPLong[dataLPPLong$time == "allTr",],
dv = LPP,
wid = partInd,
within = .(CS),
between = .(usGroup),
x = CS,
split = usGroup
)
# frequentist & bayesian t-tests on LPP (difference scores) across groups
# delta [CS+av - CS+neu]
lppBothAvNeu_t <- t.test(x = dataLPP$Av_allTr[dataLPP$usGroup == "real"] -
dataLPP$Neu_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Av_allTr[dataLPP$usGroup == "ima"] -
dataLPP$Neu_allTr[dataLPP$usGroup == "ima"],
alternative = "two.sided", paired = FALSE) # two-sided
lppBothAvNeu_d <- cohens_d(x = dataLPP$Av_allTr[dataLPP$usGroup == "real"] -
dataLPP$Neu_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Av_allTr[dataLPP$usGroup == "ima"] -
dataLPP$Neu_allTr[dataLPP$usGroup == "ima"],
paired = FALSE)
lppBothAvNeu_BF <- ttestBF(x = dataLPP$Av_allTr[dataLPP$usGroup == "real"] -
dataLPP$Neu_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Av_allTr[dataLPP$usGroup == "ima"] -
dataLPP$Neu_allTr[dataLPP$usGroup == "ima"],
nullInterval = NULL, paired = FALSE) # two-sided
# delta [CS+av - CS-]
lppBothAvMin_t <- t.test(x = dataLPP$Av_allTr[dataLPP$usGroup == "real"] -
dataLPP$Min_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Av_allTr[dataLPP$usGroup == "ima"] -
dataLPP$Min_allTr[dataLPP$usGroup == "ima"],
alternative = "two.sided", paired = FALSE) # two-sided
lppBothAvMin_d <- cohens_d(x = dataLPP$Av_allTr[dataLPP$usGroup == "real"] -
dataLPP$Min_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Av_allTr[dataLPP$usGroup == "ima"] -
dataLPP$Min_allTr[dataLPP$usGroup == "ima"],
paired = FALSE)
lppBothAvMin_BF <- ttestBF(x = dataLPP$Av_allTr[dataLPP$usGroup == "real"] -
dataLPP$Min_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Av_allTr[dataLPP$usGroup == "ima"] -
dataLPP$Min_allTr[dataLPP$usGroup == "ima"],
nullInterval = NULL, paired = FALSE) # two-sided
# delta [CS+neu - CS-]
lppBothNeuMin_t <- t.test(x = dataLPP$Neu_allTr[dataLPP$usGroup == "real"] -
dataLPP$Min_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Neu_allTr[dataLPP$usGroup == "ima"] -
dataLPP$Min_allTr[dataLPP$usGroup == "ima"],
alternative = "two.sided", paired = FALSE) # two-sided
lppBothNeuMin_d <- cohens_d(x = dataLPP$Neu_allTr[dataLPP$usGroup == "real"] -
dataLPP$Min_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Neu_allTr[dataLPP$usGroup == "ima"] -
dataLPP$Min_allTr[dataLPP$usGroup == "ima"],
paired = FALSE)
lppBothNeuMin_BF <- ttestBF(x = dataLPP$Neu_allTr[dataLPP$usGroup == "real"] -
dataLPP$Min_allTr[dataLPP$usGroup == "real"],
y = dataLPP$Neu_allTr[dataLPP$usGroup == "ima"] -
dataLPP$Min_allTr[dataLPP$usGroup == "ima"],
nullInterval = NULL, paired = FALSE) # two-sided
#########################
### Table for t-tests ###
#########################
tableData <- data.frame(
comparison = rep(c("imagery: CS+av vs CS+neu", "imagery: CS+av vs CS-", "imagery: CSneu vs CS-",
"classical: CS+av vs CS+neu", "classical: CS+av vs CS-", "classical: CSneu vs CS-",
"groups: delta CS+av / CS+neu", "groups: delta CS+av / CS-", "groups: delta CSneu / CS-"), 3),
t = c(lppImaAvNeu_t$statistic, lppImaAvMin_t$statistic, lppImaNeuMin_t$statistic,
lppRealAvNeu_t$statistic, lppRealAvMin_t$statistic, lppRealNeuMin_t$statistic,
lppBothAvNeu_t$statistic, lppBothAvMin_t$statistic, lppBothNeuMin_t$statistic),
df = c(lppImaAvNeu_t$parameter, lppImaAvMin_t$parameter, lppImaNeuMin_t$parameter,
lppRealAvNeu_t$parameter, lppRealAvMin_t$parameter, lppRealNeuMin_t$parameter,
lppBothAvNeu_t$parameter, lppBothAvMin_t$parameter, lppBothNeuMin_t$parameter),
p = c(lppImaAvNeu_t$p.value, lppImaAvMin_t$p.value, lppImaNeuMin_t$p.value,
lppRealAvNeu_t$p.value, lppRealAvMin_t$p.value, lppRealNeuMin_t$p.value,
lppBothAvNeu_t$p.value*3, lppBothAvMin_t$p.value*3, lppBothNeuMin_t$p.value*3),  # Bonferroni
d = c(lppImaAvNeu_d$Cohens_d, lppImaAvMin_d$Cohens_d, lppImaNeuMin_d$Cohens_d,
lppRealAvNeu_d$Cohens_d, lppRealAvMin_d$Cohens_d, lppRealNeuMin_d$Cohens_d,
lppBothAvNeu_d$Cohens_d, lppBothAvMin_d$Cohens_d, lppBothNeuMin_d$Cohens_d),
BF = c(exp(lppImaAvNeu_BF@bayesFactor[["bf"]][1]), exp(lppImaAvMin_BF@bayesFactor[["bf"]][1]), exp(lppImaNeuMin_BF@bayesFactor[["bf"]][1]),
exp(lppRealAvNeu_BF@bayesFactor[["bf"]][1]), exp(lppRealAvMin_BF@bayesFactor[["bf"]][1]), exp(lppRealNeuMin_BF@bayesFactor[["bf"]][1]),
exp(lppBothAvNeu_BF@bayesFactor[["bf"]][1]), exp(lppBothAvMin_BF@bayesFactor[["bf"]][1]), exp(lppBothNeuMin_BF@bayesFactor[["bf"]][1]))
)
# round the numbers
tableData$t <-round(tableData$t, 2)
tableData$df <-round(tableData$df, 0)
tableData$p[tableData$p < .001] <- 0
tableData$p[tableData$p > 1] <- 1
tableData$p <-round(tableData$p, 3)
tableData$p <- as.character(tableData$p)
tableData$p[tableData$p == "0"] <- "< .001"
tableData$p <- str_replace(tableData$p, "0\\.", "\\.")
tableData$d <-round(tableData$d, 2)
tableData$BF <- format(tableData$BF, digits = 2)
tableLPP <- flextable(tableData[1:9,])
# --- author: Christian Panitz
# --- encoding: en_US.UTF-8
# --- R version: 4.3.1 (2023-06-16) -- "Beagle Scouts"
# --- RStudio version: 2023.06.0
# --- script version: Feb 2024
# --- content: main fear rating analyses
###################
### preparing R ###
###################
# random number generator seed (necessary for Bayesian ANOVAs)
# created with [set.seed(NULL)] and [sample(2^31 - 1, 1)]
rngSeed <- 814677222
# loading required packages
library(tidyr) # ver. 1.3.0
library(psych) # ver. 2.3.9
library(effectsize) # ver. 0.8.6
library(ez) # ver. 4.4-0
library(BayesFactor) # ver. 0.9.12-4.5
library(bayestestR) # 0.13.1
library(ggplot2) # ver. 3.4.2
library(scico) # ver. 1.5.0
library(scales) # ver. 1.2.1
#library(flextable) # 0.9.4
library(stringr) # 1.5.0
library(here) # 1.0.1
########################
### data preparation ###
########################
# load rating data from text file
# (see imaCond3_allratings_readme.txt for more details)
pathname <- here()
importRatings <- read.csv(paste0(pathname, "/experimentData/imaCond3_demographicsAndRatings.txt"), sep=",")
# create data frames in wide & long format for fear ratings
dataFear <- data.frame(
partInd = factor(1:dim(importRatings)[1]), # could not resovle issue in which Bayes ANOVA crashes using alphanumeric codes as prticipant ID
partCode = factor(importRatings$partCode),
usGroup = factor(importRatings$group, levels = c("ima", "real")),
Av_Pre = importRatings$anx_csplus_av_2,
Av_Mid = importRatings$anx_csplus_av_3,
Av_Post = importRatings$anx_csplus_av_4,
Neu_Pre = importRatings$anx_csplus_neu_2,
Neu_Mid = importRatings$anx_csplus_neu_3,
Neu_Post = importRatings$anx_csplus_neu_4,
Min_Pre = importRatings$anx_csminus_2,
Min_Mid = importRatings$anx_csminus_3,
Min_Post = importRatings$anx_csminus_4
)
dataFearLong <- gather(data = dataFear, key = "cond", value = "fear",
Av_Pre:Min_Post)
dataFearLong <- separate(data = dataFearLong, col = cond, into = c("CS","time"),
sep = "_")
dataFearLong$CS <- factor(dataFearLong$CS, levels = c("Av", "Neu", "Min"))
dataFearLong$time <- factor(dataFearLong$time, levels = c("Pre", "Mid", "Post"))
####################################################################
### Imagery-based conditioning - fear ratings - primary analyses ###
####################################################################
# descriptive statistics for fear ratings in imagery-based conditioning group
describe(dataFear[dataFear$usGroup == "ima",])
# frequentist ANOVA in imagery-based conditioning group, including p. eta^2
# IV = CS; DV = fear rating
anovaFearIma <- ezANOVA(
data = dataFearLong[dataFearLong$usGroup == "ima" & dataFearLong$time == "Post",],
dv = fear,
wid = partInd,
within = .(CS),
type = 3,
detailed = TRUE
); anovaFearIma$ANOVA$pEtaSq <-
c(anovaFearIma$ANOVA$SSn[1] / (anovaFearIma$ANOVA$SSd[1]+anovaFearIma$ANOVA$SSn[1]),
anovaFearIma$ANOVA$SSn[2] / (anovaFearIma$ANOVA$SSd[2]+anovaFearIma$ANOVA$SSn[2])
); print(anovaFearIma)
# bayesian ANOVA on fear ratings in imagery-based conditioning group
set.seed(rngSeed); anovaBFFearIma <- anovaBF(
formula = fear ~ CS + partInd,
data = dataFearLong[dataFearLong$usGroup == "ima" & dataFearLong$time == "Post",],
whichRandom = "partInd",
iterations = 100000
); print(anovaBFFearIma)
# frequentist & bayesian t-tests on fear ratings in imagery-based conditioning group
# CS+av vs CS+neu
fearImaAvNeu_t <- t.test(x = dataFear$Av_Post[dataFear$usGroup == "ima"],
y = dataFear$Neu_Post[dataFear$usGroup == "ima"],
alternative = "greater", paired = TRUE) # one-sided
fearImaAvNeu_d <- cohens_d(x = dataFear$Av_Post[dataFear$usGroup == "ima"],
y = dataFear$Neu_Post[dataFear$usGroup == "ima"],
paired = TRUE)
fearImaAvNeu_BF <- ttestBF(x = dataFear$Av_Post[dataFear$usGroup == "ima"],
y = dataFear$Neu_Post[dataFear$usGroup == "ima"],
nullInterval = c(0, Inf), paired = TRUE) # one-sided x > y
# CS+av vs CS-
fearImaAvMin_t <- t.test(x = dataFear$Av_Post[dataFear$usGroup == "ima"],
y = dataFear$Min_Post[dataFear$usGroup == "ima"],
alternative = "greater", paired = TRUE) # one-sided
fearImaAvMin_d <- cohens_d(x = dataFear$Av_Post[dataFear$usGroup == "ima"],
y = dataFear$Min_Post[dataFear$usGroup == "ima"],
paired = TRUE)
fearImaAvMin_BF <- ttestBF(x = dataFear$Av_Post[dataFear$usGroup == "ima"],
y = dataFear$Min_Post[dataFear$usGroup == "ima"],
nullInterval = c(0, Inf), paired = TRUE) # one-sided x > y
# CS+neu vs CS-
fearImaNeuMin_t <- t.test(x = dataFear$Neu_Post[dataFear$usGroup == "ima"],
y = dataFear$Min_Post[dataFear$usGroup == "ima"],
alternative = "two.sided", paired = TRUE) # two-sided
fearImaNeuMin_d <- cohens_d(x = dataFear$Neu_Post[dataFear$usGroup == "ima"],
y = dataFear$Min_Post[dataFear$usGroup == "ima"],
paired = TRUE)
fearImaNeuMin_BF <- ttestBF(x = dataFear$Neu_Post[dataFear$usGroup == "ima"],
y = dataFear$Min_Post[dataFear$usGroup == "ima"],
nullIntervall = NULL, paired = TRUE) # two-sided
################################################################
### Classical conditioning - fear ratings - primary analyses ###
################################################################
# descriptive statistics for fear ratings in classical conditioning group
describe(dataFear[dataFear$usGroup == "real",])
# frequentist ANOVA in classical conditioning group, including p. eta^2
# IV = CS; DV = fear rating
anovaFearReal <- ezANOVA(
data = dataFearLong[dataFearLong$usGroup == "real" & dataFearLong$time == "Post",],
dv = fear,
wid = partInd,
within = .(CS),
type = 3,
detailed = TRUE
); anovaFearReal$ANOVA$pEtaSq <-
c(anovaFearReal$ANOVA$SSn[1] / (anovaFearReal$ANOVA$SSd[1]+anovaFearReal$ANOVA$SSn[1]),
anovaFearReal$ANOVA$SSn[2] / (anovaFearReal$ANOVA$SSd[2]+anovaFearReal$ANOVA$SSn[2])
); print(anovaFearReal)
# bayesian ANOVA on fear ratings in classical conditioning group
set.seed(rngSeed); anovaBFFearReal <- anovaBF(
formula = fear ~ CS + partInd,
data = dataFearLong[dataFearLong$usGroup == "real" & dataFearLong$time == "Post",],
whichRandom = "partInd",
iterations = 100000
); print(anovaBFFearReal)
# frequentist & bayesian t-tests on fear ratings in classical conditioning group
# CS+av vs CS+neu
fearRealAvNeu_t <- t.test(x = dataFear$Av_Post[dataFear$usGroup == "real"],
y = dataFear$Neu_Post[dataFear$usGroup == "real"],
alternative = "greater", paired = TRUE) # one-sided
fearRealAvNeu_d <- cohens_d(x = dataFear$Av_Post[dataFear$usGroup == "real"],
y = dataFear$Neu_Post[dataFear$usGroup == "real"],
paired = TRUE)
fearRealAvNeu_BF <- ttestBF(x = dataFear$Av_Post[dataFear$usGroup == "real"],
y = dataFear$Neu_Post[dataFear$usGroup == "real"],
nullInterval = c(0, Inf), paired = TRUE) # one-sided x > y
# CS+av vs CS-
fearRealAvMin_t <- t.test(x = dataFear$Av_Post[dataFear$usGroup == "real"],
y = dataFear$Min_Post[dataFear$usGroup == "real"],
alternative = "greater", paired = TRUE) # one-sided
fearRealAvMin_d <- cohens_d(x = dataFear$Av_Post[dataFear$usGroup == "real"],
y = dataFear$Min_Post[dataFear$usGroup == "real"],
paired = TRUE)
fearRealAvMin_BF <- ttestBF(x = dataFear$Av_Post[dataFear$usGroup == "real"],
y = dataFear$Min_Post[dataFear$usGroup == "real"],
nullInterval = c(0, Inf), paired = TRUE) # one-sided x > y
# CS+neu vs CS-
fearRealNeuMin_t <- t.test(x = dataFear$Neu_Post[dataFear$usGroup == "real"],
y = dataFear$Min_Post[dataFear$usGroup == "real"],
alternative = "two.sided", paired = TRUE) # two-sided
fearRealNeuMin_d <- cohens_d(x = dataFear$Neu_Post[dataFear$usGroup == "real"],
y = dataFear$Min_Post[dataFear$usGroup == "real"],
paired = TRUE)
fearRealNeuMin_BF <- ttestBF(x = dataFear$Neu_Post[dataFear$usGroup == "real"],
y = dataFear$Min_Post[dataFear$usGroup == "real"],
nullIntervall = NULL, paired = TRUE) # two-sided
#######################################################
### Across groups - fear ratings - primary analyses ###
#######################################################
# descriptive statistics  for fear ratings across conditioning groups
describe(dataFear)
# frequentist ANOVA on fear ratings across conditioning groups
anovaFear <- ezANOVA(
data = dataFearLong[dataFearLong$time == "Post",],
dv = fear,
wid = partInd,
within = .(CS),
between = .(usGroup),
type = 3,
detailed = TRUE
); anovaFear$ANOVA$pEtaSq <- c(anovaFear$ANOVA$SSn[1] /
(anovaFear$ANOVA$SSd[1]+anovaFear$ANOVA$SSn[1]),
anovaFear$ANOVA$SSn[2] /
(anovaFear$ANOVA$SSd[2]+anovaFear$ANOVA$SSn[2]),
anovaFear$ANOVA$SSn[3] /
(anovaFear$ANOVA$SSd[3]+anovaFear$ANOVA$SSn[3]),
anovaFear$ANOVA$SSn[4] /
(anovaFear$ANOVA$SSd[4]+anovaFear$ANOVA$SSn[4])
); print(anovaFear)
# bayesian ANOVA on fear ratings across conditioning groups
set.seed(rngSeed); anovaBFFear <- anovaBF(
formula = fear ~ usGroup*CS + partInd,
data = dataFearLong[dataFearLong$time == "Post",],
whichRandom = "partInd",
whichModels = "all",
iterations = 100000
); print(anovaBFFear)
# inclusion factors for bayesian ANOVA effects
bf_inclusion(anovaBFFear)
# quick graph of group x CS ANOVA on fear ratings
ezPlot(
data = dataFearLong[dataFearLong$time == "Post",],
dv = fear,
wid = partInd,
within = .(CS),
between = .(usGroup),
x = CS,
split = usGroup
)
# frequentist & bayesian t-tests on fear ratings (difference scores) across groups
# delta [CS+av - CS+neu]
fearBothAvNeu_t <- t.test(x = dataFear$Av_Post[dataFear$usGroup == "real"] -
dataFear$Neu_Post[dataFear$usGroup == "real"],
y = dataFear$Av_Post[dataFear$usGroup == "ima"] -
dataFear$Neu_Post[dataFear$usGroup == "ima"],
alternative = "two.sided", paired = FALSE) # two-sided
fearBothAvNeu_d <- cohens_d(x = dataFear$Av_Post[dataFear$usGroup == "real"] -
dataFear$Neu_Post[dataFear$usGroup == "real"],
y = dataFear$Av_Post[dataFear$usGroup == "ima"] -
dataFear$Neu_Post[dataFear$usGroup == "ima"],
paired = FALSE)
fearBothAvNeu_BF <- ttestBF(x = dataFear$Av_Post[dataFear$usGroup == "real"] -
dataFear$Neu_Post[dataFear$usGroup == "real"],
y = dataFear$Av_Post[dataFear$usGroup == "ima"] -
dataFear$Neu_Post[dataFear$usGroup == "ima"],
nullInterval = NULL, paired = FALSE) # two-sided
# delta [CS+av - CS-]
fearBothAvMin_t <- t.test(x = dataFear$Av_Post[dataFear$usGroup == "real"] -
dataFear$Min_Post[dataFear$usGroup == "real"],
y = dataFear$Av_Post[dataFear$usGroup == "ima"] -
dataFear$Min_Post[dataFear$usGroup == "ima"],
alternative = "two.sided", paired = FALSE) # two-sided
fearBothAvMin_d <- cohens_d(x = dataFear$Av_Post[dataFear$usGroup == "real"] -
dataFear$Min_Post[dataFear$usGroup == "real"],
y = dataFear$Av_Post[dataFear$usGroup == "ima"] -
dataFear$Min_Post[dataFear$usGroup == "ima"],
paired = FALSE)
fearBothAvMin_BF <- ttestBF(x = dataFear$Av_Post[dataFear$usGroup == "real"] -
dataFear$Min_Post[dataFear$usGroup == "real"],
y = dataFear$Av_Post[dataFear$usGroup == "ima"] -
dataFear$Min_Post[dataFear$usGroup == "ima"],
nullInterval = NULL, paired = FALSE) # two-sided
# delta [CS+neu - CS-]
fearBothNeuMin_t <- t.test(x = dataFear$Neu_Post[dataFear$usGroup == "real"] -
dataFear$Min_Post[dataFear$usGroup == "real"],
y = dataFear$Neu_Post[dataFear$usGroup == "ima"] -
dataFear$Min_Post[dataFear$usGroup == "ima"],
alternative = "two.sided", paired = FALSE) # two-sided
fearBothNeuMin_d <- cohens_d(x = dataFear$Neu_Post[dataFear$usGroup == "real"] -
dataFear$Min_Post[dataFear$usGroup == "real"],
y = dataFear$Neu_Post[dataFear$usGroup == "ima"] -
dataFear$Min_Post[dataFear$usGroup == "ima"],
paired = FALSE)
fearBothNeuMin_BF <- ttestBF(x = dataFear$Neu_Post[dataFear$usGroup == "real"] -
dataFear$Min_Post[dataFear$usGroup == "real"],
y = dataFear$Neu_Post[dataFear$usGroup == "ima"] -
dataFear$Min_Post[dataFear$usGroup == "ima"],
nullInterval = NULL, paired = FALSE) # two-sided
#########################
### Table for t-tests ###
#########################
tableData <- data.frame(
comparison = rep(c("imagery: CS+av vs CS+neu", "imagery: CS+av vs CS-", "imagery: CSneu vs CS-",
"classical: CS+av vs CS+neu", "classical: CS+av vs CS-", "classical: CSneu vs CS-",
"groups: delta CS+av / CS+neu", "groups: delta CS+av / CS-", "groups: delta CSneu / CS-"), 5),
t = c(fearImaAvNeu_t$statistic, fearImaAvMin_t$statistic, fearImaNeuMin_t$statistic,
fearRealAvNeu_t$statistic, fearRealAvMin_t$statistic, fearRealNeuMin_t$statistic,
fearBothAvNeu_t$statistic, fearBothAvMin_t$statistic, fearBothNeuMin_t$statistic),
df = c(fearImaAvNeu_t$parameter, fearImaAvMin_t$parameter, fearImaNeuMin_t$parameter,
fearRealAvNeu_t$parameter, fearRealAvMin_t$parameter, fearRealNeuMin_t$parameter,
fearBothAvNeu_t$parameter, fearBothAvMin_t$parameter, fearBothNeuMin_t$parameter),
p = c(fearImaAvNeu_t$p.value, fearImaAvMin_t$p.value, fearImaNeuMin_t$p.value,
fearRealAvNeu_t$p.value, fearRealAvMin_t$p.value, fearRealNeuMin_t$p.value,
fearBothAvNeu_t$p.value*3, fearBothAvMin_t$p.value*3, fearBothNeuMin_t$p.value*3),  # Bonferroni
d = c(fearImaAvNeu_d$Cohens_d, fearImaAvMin_d$Cohens_d, fearImaNeuMin_d$Cohens_d,
fearRealAvNeu_d$Cohens_d, fearRealAvMin_d$Cohens_d, fearRealNeuMin_d$Cohens_d,
fearBothAvNeu_d$Cohens_d, fearBothAvMin_d$Cohens_d, fearBothNeuMin_d$Cohens_d),
BF = c(exp(fearImaAvNeu_BF@bayesFactor[["bf"]][1]), exp(fearImaAvMin_BF@bayesFactor[["bf"]][1]), exp(fearImaNeuMin_BF@bayesFactor[["bf"]][1]),
exp(fearRealAvNeu_BF@bayesFactor[["bf"]][1]), exp(fearRealAvMin_BF@bayesFactor[["bf"]][1]), exp(fearRealNeuMin_BF@bayesFactor[["bf"]][1]),
exp(fearBothAvNeu_BF@bayesFactor[["bf"]][1]), exp(fearBothAvMin_BF@bayesFactor[["bf"]][1]), exp(fearBothNeuMin_BF@bayesFactor[["bf"]][1]))
)
# round the numbers
tableData$t <-round(tableData$t, 2)
tableData$df <-round(tableData$df, 0)
tableData$p[tableData$p < .001] <- 0
tableData$p[tableData$p > 1] <- 1
tableData$p <-round(tableData$p, 3)
tableData$p <- as.character(tableData$p)
tableData$p[tableData$p == "0"] <- "< .001"
tableData$p <- str_replace(tableData$p, "0\\.", "\\.")
tableData$d <-round(tableData$d, 2)
tableData$BF <- format(tableData$BF, digits = 2)
tableFear <- flextable(tableData[1:9,])
# --- author: Christian Panitz
# --- encoding: en_US.UTF-8
# --- R version: 4.3.1 (2023-06-16) -- "Beagle Scouts"
# --- RStudio version: 2023.06.0
# --- script version: Feb 2024
# --- content: supplementary LPP analyses with factor Time
###################
### preparing R ###
###################
# random number generator seed (necessary for Bayesian ANOVAs)
# created with [set.seed(NULL)] and [sample(2^31 - 1, 1)]
rngSeed <- 814677222
# loading required packages
library(tidyr) # ver. 1.3.0
library(psych) # ver. 2.3.9
library(effectsize) # ver. 0.8.6
library(ez) # ver. 4.4-0
library(BayesFactor) # ver. 0.9.12-4.5
library(bayestestR) # 0.13.1
library(stringr) # ver. 1.5.0
library(here) # ver. 1.0.1
###################################
### Setting time window for LPP ###
###################################
# set by user
sRate <- 1024 # sampling rate of EEG data
startSeg <- -200 # time of first data point relative to CS
TWOI <- c(300,700) # Time Window Of Interest (in ms)
chanInd <- 31 # 31 = index of Pz in EEG array
chanNames <- c("Pz")
# computed
SWOI <- c(round(TWOI[1]-startSeg*sRate/1000),round(TWOI[2]-startSeg*sRate/1000)) # Sample Window Of Interest
########################
### data preparation ###
########################
# Rating data contains group membership
# (see imaCond3_allratings_readme.txt for more details)
pathname <- here()
importRatings <- read.csv(paste0(pathname,"/experimentData/imaCond3_demographicsAndRatings.txt"), sep = ",")
# read LPP data
# create emtpy matrices, rows = participants, columns = sample points (entire ERP)
tempData <- read.csv(paste0(pathname, "/experimentData/erpData/", importRatings$partCode[1], "_IMAKON03_Average_Akqu1_EKP_P9P10_S51.dat"),
header = FALSE, sep = " ")
lppMatAV1 <- matrix(data = NA, nrow = dim(importRatings)[1], ncol = dim(tempData)[1])
lppMatNEU1 <- matrix(data = NA, nrow = dim(importRatings)[1], ncol = dim(tempData)[1])
lppMatMIN1 <- matrix(data = NA, nrow = dim(importRatings)[1], ncol = dim(tempData)[1])
lppMatAV2 <- matrix(data = NA, nrow = dim(importRatings)[1], ncol = dim(tempData)[1])
lppMatNEU2 <- matrix(data = NA, nrow = dim(importRatings)[1], ncol = dim(tempData)[1])
lppMatMIN2 <- matrix(data = NA, nrow = dim(importRatings)[1], ncol = dim(tempData)[1])
# get indices for selected channel names
chanInd <- match(chanNames, chanLocs$name)
# get indices for selected channel names
loadname <- paste0(pathname,"/channelLocations/chanLocs_biosemi64.txt")
chanLocs <- read.csv(loadname, sep = ";")
chanInd <- match(chanNames, chanLocs$name)
# read single-subject data and extract channels
for (partI in 1:length(importRatings$partCode)) {
tempData <- read.csv(paste0(pathname, "/experimentData/erpData/", importRatings$partCode[partI], "_IMAKON03_Average_Akqu1_EKP_P9P10_S51.dat"),
header = FALSE, sep = " ")
lppMatAV1[partI,] <- colMeans(t(tempData[,chanInd]))
tempData <- read.csv(paste0(pathname, "/experimentData/erpData/", importRatings$partCode[partI], "_IMAKON03_Average_Akqu1_EKP_P9P10_S52.dat"),
header = FALSE, sep = " ")
lppMatNEU1[partI,] <- colMeans(t(tempData[,chanInd]))
tempData <- read.csv(paste0(pathname, "/experimentData/erpData/", importRatings$partCode[partI], "_IMAKON03_Average_Akqu1_EKP_P9P10_S53.dat"),
header = FALSE, sep = " ")
lppMatMIN1[partI,] <- colMeans(t(tempData[,chanInd]))
tempData <- read.csv(paste0(pathname, "/experimentData/erpData/", importRatings$partCode[partI], "_IMAKON03_Average_Akqu2_EKP_P9P10_S51.dat"),
header = FALSE, sep = " ")
lppMatAV2[partI,] <- colMeans(t(tempData[,chanInd]))
tempData <- read.csv(paste0(pathname, "/experimentData/erpData/", importRatings$partCode[partI], "_IMAKON03_Average_Akqu2_EKP_P9P10_S52.dat"),
header = FALSE, sep = " ")
lppMatNEU2[partI,] <- colMeans(t(tempData[,chanInd]))
tempData <- read.csv(paste0(pathname, "/experimentData/erpData/", importRatings$partCode[partI], "_IMAKON03_Average_Akqu2_EKP_P9P10_S53.dat"),
header = FALSE, sep = " ")
lppMatMIN2[partI,] <- colMeans(t(tempData[,chanInd]))
}
